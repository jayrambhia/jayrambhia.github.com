<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
    <head >
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>SIFT based Tracker &mdash; Aniket Pant</title>
        <meta name="author" content="">
        <meta name="description" content="">
        <meta name="keywords" content="jay, rambhia, computer vision, python, trakcing, keypoints, c, c++, simplecv, opencv">
        <meta name="viewport" content="width=device-width">

        
        

        <!-- stylesheets -->
        <link rel="stylesheet" href="/assets/styles/css/style.min.css">
    </head>
    <body>
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="http://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <div class="header-container gw">
            <div class="g one-whole zen-space full-width"></div>
            <div class="wrapper">
                <header class="g one-whole flexbox" role="banner">
                    <h1 class="g one-third portable-one-whole flexbox__item"><a class="logo media" href="/" rel="nofollow"><img class="media__item" src="/assets/images/logo.jpg" alt="Rawrrr! Aniket here." /></a></h1>
                    <nav class="g two-thirds portable-one-whole flexbox__item navbar">
                        <ul class="nav nav--block portable-nav--stacked">
                            <li><a href="/">Home</a></li>
                            <li><a href="/about-me">About Me</a></li>
                            <li><a href="/Blog">Blog</a></li>
                            <li><a href="/archive">Archive</a></li>
                        </ul>
                    </nav>
                    <div class="g two-thirds portable-one-whole flexbox__item">
                        <p class="islet about-me">I'm <strong>Aniket</strong>. I love to code, listen to music and I even write free-verses at times. A majority of my work is <em>writing syntax for design</em>.</p>
                    </div>
                    <p rel="google-authorship" class="accessibility">By Aniket Pant</p>
                </header> <!-- header -->
            </div>
        </div> <!-- header-container -->

        <div class="main-container gw">
            <div class="wrapper">
                <section class="g one-whole" role="main">
                <div class="post sift-based-tracker">
	<header class="g one-quarter portable-one-whole post--header">
  		<h1 class="post_title">SIFT based Tracker</h1>
  		<div class="meta"><date class="date">Posted on 24 September 2012</date><br/>Under <span class="category">Blog</a><br/>Tagged </span><span class="tags">Python</span></div>
      <div class="share island">
        <a href="https://twitter.com/share" class="twitter-share-button" data-via="jayrambhia" data-related="jayrambhia">Tweet</a>
        <div class="g-plusone" data-size="medium"></div>
        <div class="fb-like" data-send="false" data-layout="button_count" data-width="450" data-show-faces="true"></div>
      </div>
      <div id="boastful"></div>
	</header><!-- post-header -->
	<div class="g three-quarters portable-one-whole">
		<article class="post--content">
	  	<p><strong>Scale-invariant feature transform</strong> (or SIFT) is an algorithm in computer vision to detect and describe local features in images. The algorithm was published by David Lowe in 1999.SIFT is a method to detect distinct, invariant image feature points, which easily can be matched between images to perform tasks such as object detection and recognition, or to compute geometrical transformation between images.</p>

<p>SIFT keypoints of objects are first extracted from a set of reference images and stored in a database. An object is recognized in a new image by individually comparing each feature from the new image to this database and finding candidate matching features based on Euclidean distance of their feature vectors.</p>

<p>Lowe’s method for image feature generation transforms an image into a large collection of feature vectors, each of which is invariant to image translation, scaling, and rotation, partially invariant to illumination changes and robust to local geometric distortion.</p>

<p>The scale invariant features are efficiently identified by using a staged filter approach. The first stage identifies key locations in scale space by looking for locations that are maxima or minima of a difference of-Gaussian function. Each point is used to generate a feature vector that describesthe local image region sampled relative to its scale-space co-ordinate frame.</p>

<p>The SIFT keys derived from an image are used in a nearest-neighbour approach to indexing to identify candidate object models. Collections of keys that agree on a potential model pose are first identified through a Hough transform hash table, and then through a least-squares fit to a final estimate of model parameters. When at least 3 keys agree on the model parameters with low residual, there is strong evidence for the presence of the object.</p>

<p>For detailed information about SIFT, visit <strong><a href="http://www.aishack.in/2010/05/sift-scale-invariant-feature-transform/">aishack</a></strong>.</p>

<p><strong>Finding KeyPoints using SIFT in OpenCV</strong>:
OpenCV has a good support for SIFT. Read more about <a href="http://docs.opencv.org/modules/nonfree/doc/feature_detection.html?highlight=sift">SIFT-OpenCV</a>.
Include libraries and other stuff</p>

<pre><code>#include&lt;opencv2/opencv.hpp&gt;
#include&lt;opencv2/features2d/features2d.hpp&gt;
#include&lt;opencv2/imgproc/imgproc_c.h&gt;
#include&lt;opencv2/nonfree/nonfree.hpp&gt;
using namespace cv;
using namespace std;
</code></pre>

<p>Find and draw KeyPoints</p>

<pre><code>VideoCapture cap = VideoCapture(0);
Mat img, descriptors;
SIFT sift;
vector&lt;KeyPoint&gt; keypoints;

cap &gt;&gt; img;

sift(img, Mat(), keypoints, descriptors); /* find keypoints */
drawKeypoints(img, keypoints, img); /* draw keypoints */
imshow("image",img);
</code></pre>

<p><strong>KeyPoints Matching using FLANN</strong>:
After successfully finding SIFT keypoints in an image, we can use these keypoints to match the keypoints from other image.</p>

<ol>
  <li>Select ROI in the image. Slice the image and extract the ROI.</li>
  <li>Find SIFT Keypoints in ROI image.</li>
  <li>Find SIFT Keypoints in the image.</li>
  <li>Match Keypoints using FLANN.</li>
  <li>Predict new bounding box/ ROI and repeat.</li>
</ol>

<p><strong>FLANN</strong>:
Fast Library for Approximate Nearest Neighbors is a library that contains a collection of algorithms optimized for fast nearest neighbor search in large datasets and for high dimensional features. Read more about FLANN <a href="http://people.cs.ubc.ca/~mariusm/index.php/FLANN/FLANN">here</a>.</p>

<p><strong>Implementing FLANN using OpenCV</strong>:
OpenCV has a good support for FLANN. It has FLANN based Matcher which can be used to match two sets of keypoints.</p>

<pre><code>SIFT sift;
vector keypoints_roi, keypoints_img;
Mat descriptor_roi, descriptor_img;
FlannBasedMatcher matcher;
vector&lt;DMatch&gt; matches;

/* get keypoints of ROI image */
sift(roiImg, Mat(), keypoints_roi, descriptor_roi);
/* get keypoints of the image */
sift(img, Mat(), keypoints_img, descriptor_img);
/* Match keypoints using FLANN */
matcher.match(descriptor_roi, descriptor_img, matches);
</code></pre>

<p>After getting the matched keypoints based on K-nearest neighbor, you might want to filter out points with greater euclidean distance. You can easily do this by accessing the DMatch.</p>

<p>FlannBasedMatcher stores the result in DMatch which is a class for matching keypoint descriptors. Read more about DMatch <a href="http://docs.opencv.org/modules/features2d/doc/common_interfaces_of_descriptor_matchers.html?highlight=dmatch#DMatch">here</a>.</p>

<p><strong>DMatch</strong>:
As I mentioned above, DMatch is a class for matching keypoint descriptors. It has following parameters.</p>

<pre><code>int queryIdx; // query descriptor index
int trainIdx; // train descriptor index
int imgIdx; // train image index

float distance;
</code></pre>

<p><strong>distance</strong> - K-means distance between the matched keypoints
<strong>queryIdx</strong> - Index of query descriptor keypoint.
<strong>trainIdx</strong> - Index of train descriptor keypoint</p>

<p>So, this can be simplified as (in the above reference), <strong>keypoints_roi[match[i].queryIdx]</strong> is a match for <strong>keypoints_img[match[i].trainIdx]</strong>
By using DMatch, we can easily access matched keypoints.</p>

<p><strong>Filter out matches by taking the k-means distance</strong>:</p>

<pre><code>vector&lt;DMatch&gt; good_matches;
double min = 200.0;
for (int i=0; i&lt;descriptor_roi.size(); i++)
{
    if(matches[i].distance &lt; min)
    {
        good_matches.push_back(matches[i]);
    }
}
</code></pre>

<p><strong>Draw matched keypoints</strong>:</p>

<pre><code>Mat img_matches;
drawMatches(roiImg, keypoints_roi, img, keypoints_img,
            good_matches, img_matches, Scalar::all(-1),
            Scalar::all(-1), vector(),
            DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);
</code></pre>

<p><strong>Draw matched keypoints on image</strong>:</p>

<pre><code>vector&lt;KeyPoint&gt; keypoints1;
for (i=0; i&lt;good_matches.size(); i++)
{
     keypoints1.push_back(keypoints_img[good_matches[i].trainIdx]);
}
drawKeypoints(img, keypoints1, img,
              Scalar::all(-1),
              DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);
</code></pre>

<p><strong>Draw matched keypoints on ROI image</strong>:</p>

<pre><code>vector&lt;KeyPoint&gt; keypoints2;
for (i=0; i&lt;good_matches.size(); i++)
{
    keypoints2.push_back(keypoints_roi[good_matches[i].queryIdx]);
}
drawKeypoints(roiImg, keypoints2, roiImg,
              Scalar::all(-1),
              DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);
</code></pre>

<p><strong>Show Everything</strong>:</p>

<pre><code>imshow("image", img);
imshow("roi", roiImg);
imshow("SIFT", img_matches);
</code></pre>

<p>And this is how it looks,
<a href="http://www.jayrambhia.com/blog/wp-content/uploads/2012/09/Screenshot-from-2012-09-23-141503.png"><img src="http://www.jayrambhia.com/blog/wp-content/uploads/2012/09/Screenshot-from-2012-09-23-141503.png" alt="" /></a></p>

<p><strong>Prediction of the new Bounding Box / ROI</strong>:
I’m still weak in this part. My prediction algorithm is really stupid and doesn’t work well. I need to learn math. So if you have a good prediction algorithm to predict new ROI/BB using keypoints difference or something, you can make an efficient SIFT based tracker.</p>

<p>Other Important Links:
1. SIFT - <a href="http://blogs.oregonstate.edu/hess/code/sift/">http://www.cs.ubc.ca/~lowe/keypoints/</a>
2. SIFT code - <a href="http://blogs.oregonstate.edu/hess/code/sift/">http://blogs.oregonstate.edu/hess/code/sift/</a>
3. FLANN - <a href="http://mloss.org/software/view/143/">http://mloss.org/software/view/143/</a></p>

<p>You can find the complete source code of the SIFT based tracker on <a href="https://github.com/jayrambhia/Vision/blob/master/OpenCV/C%2B%2B/sift_tracker.cpp">GitHub</a>.</p>

<p>P.S. Finally made my <a href="https://docs.google.com/document/d/1vYA-OCUkCLZvJE8ZTGgQ0MOcoEmYAq3rfPs-s0t6XM0/edit">Resume</a>.</p>
  
		</article><!-- post-content -->
		<footer class="post--footer"></footer><!-- post-footer -->
    <section class="meta--info island">
      <p class="lead">
        <br/><br/>If you liked this post, then you should definitely follow Jay on twitter too. He would be excited to know that you like his work.
      </p>
      <a href="https://twitter.com/jayrambhia" class="twitter-follow-button" data-show-count="false">Follow @jayrambhia</a>
    </section>
  </div>
</div><!-- post -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js"></script>
<script src="/assets/js/jquery.boastful.js"></script>
<script src="/assets/js/rainbow-custom.min.js"></script>

<script type="text/javascript">
  $(document).ready(function() {
    $('#boastful').boastful({
        empty_message: '<p>Bah! Why ain\'t anyone tweeting this.</p>'  
    });
  });
</script>
                </section>
            </div>
        </div> <!-- main-container -->

        <div class="footer-container gw">
            <div class="wrapper">
                <footer class="g one-whole text--center" role="contentinfo">
                    <a href="https://plus.google.com/114828599949215633124?rel=author" class="accessibility">Google +</a>
                    <p><a href="http://twitter.com/aniket_pant">@jayrambhia</a><span class="subtle">&nbsp;|&nbsp;Paranoid Android&nbsp;&nbsp;</span> 
                </footer> <!-- footer -->
            </div>
            <div class="g one-whole zen-space full-width"></div>
        </div> <!-- footer-container -->

        <script type="text/javascript">

          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-23477947-1']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();

        </script>

        <!-- Typekit Fonts -->
        <script type="text/javascript">
          (function() {
            var config = {
              kitId: 'rsd5dqz',
              scriptTimeout: 3000
            };
            var h=document.getElementsByTagName("html")[0];h.className+=" wf-loading";var t=setTimeout(function(){h.className=h.className.replace(/(\s|^)wf-loading(\s|$)/g," ");h.className+=" wf-inactive"},config.scriptTimeout);var tk=document.createElement("script"),d=false;tk.src='//use.typekit.net/'+config.kitId+'.js';tk.type="text/javascript";tk.async="true";tk.onload=tk.onreadystatechange=function(){var a=this.readyState;if(d||a&&a!="complete"&&a!="loaded")return;d=true;clearTimeout(t);try{Typekit.load(config)}catch(b){}};var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(tk,s)
          })();

          (function(doc, script) {
            var js, 
                fjs = doc.getElementsByTagName(script)[0],
                frag = doc.createDocumentFragment(),
                add = function(url, id) {
                    if (doc.getElementById(id)) {return;}
                    js = doc.createElement(script);
                    js.src = url;
                    id && (js.id = id);
                    frag.appendChild( js );
                };
                
              // Google+ button
              add('http://apis.google.com/js/plusone.js');
              // Facebook SDK
              add('//connect.facebook.net/en_US/all.js#xfbml=1&appId=465363156848461', 'facebook-jssdk');
              // Twitter SDK
              add('//platform.twitter.com/widgets.js');

              fjs.parentNode.insertBefore(frag, fjs);
          }(document, 'script'));
        </script>

    </body>
</html>
